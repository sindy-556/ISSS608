{
  "hash": "41aa40c25a3450274221b5cdfdb4b0f0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hands-on Exercise 4b: Visual Statistical Analysis\"\nauthor: \"Sindy\"\ndate-modified: \"last-modified\"\nexecute:\n  echo: true\n  eval: true\n  warning: false\n  freeze: true\n---\n\n\n\n## 1. Getting started\n\n### 1.1 Visual Statistical Analysis with ggstatsplot\n\n`ggstatsplot` is an extension of `ggplot2` package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\n![](images/image2%20(2).jpg)\n\n### 1.2 Installing and launching R packages\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(ggstatsplot, tidyverse)\n```\n:::\n\n\n\n### 1.3 Importing data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexam_data <- read_csv(\"data/Exam_data.csv\")\n```\n:::\n\n\n\n### 1.4 One-sample test: gghistostats() method\n\nIn the code chunk below, `gghistostats()` is used to to build an visual of one-sample test on English scores.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex04b_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n::: panel-tabset\n### Code breakdown\n\n`gghistostats()`: This function creates a histogram with statistical annotations.\n\n-   `x = ENGLISH`: Specifies the variable (English scores) to be analyzed.\n-   `type = \"bayes\"`: Indicates a Bayesian one-sample test is conducted.\n-   `test.value = 60`: The test value for comparison, meaning the function tests whether the mean English score significantly differs from 60.\n-   `xlab = \"English scores\"`: Labels the x-axis as \"English scores.\"\n\n### Explanation of output\n\n-   Histogram: Displays the distribution of English scores with gray bars.\n-   Y-axis (left: count, right: proportion): Shows the frequency and proportion of students scoring within certain ranges.\n-   Dashed Blue Line: Represents the estimated mean (Maximum A Posteriori estimate, $\\hat{\\mu}_{MAP}$), which is approximately 74.74.\n-   Statistical Annotations:\n    -   $\\log_e(BF_{01}) = -31.45$: The natural log of the Bayes factor, indicating very strong evidence against the null hypothesis (which assumes a mean of 60).\n    -   $\\delta_{\\text{difference}}^{\\text{posterior}} = 7.16$: The estimated mean difference between the sample mean and 60.\n    -   $CI^{ETI}_{95\\%} [5.54, 8.75]$: The 95% credible interval (Highest Density Interval) for the mean difference.\n    -   $r^{JZS}_{Cauchy} = 0.71$: The effect size based on the Jeffreys–Zellner–Siow (JZS) prior.\n\n### Key Interpretation\n\n-   The English scores are right-skewed and centered around **74.74**, which is significantly higher than the test value of **60**.\n-   The **negative log Bayes factor (-31.45)** provides overwhelming evidence against the null hypothesis.\n-   The **credible interval \\[5.54, 8.75\\]** indicates that the true mean difference is highly likely within this range, showing strong evidence that the students’ average English scores are significantly above **60**.\n:::\n\n## 2. Bayes Factor\n\n### 2.1 Unpacking the Bayes Factor\n\n-   A **Bayes Factor (BF)** is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\n\n-   The Bayes Factor provides a way to evaluate data in favor of a null hypothesis and to incorporate external information in doing so. It quantifies the **weight of the evidence** in favor of a given hypothesis.\n\n-   When comparing two hypotheses, $H_1$ (the alternative hypothesis) and $H_0$ (the null hypothesis), the Bayes Factor is often written as $BF_{10}$. Mathematically, it is defined as:\n\n    $$\n    BF_{10} = \\frac{P(D \\mid H_1)}{P(D \\mid H_0)}\n    $$\n\nwhere:\n\n-   $P(D \\mid H_1)$ is the probability of the observed data given that the alternative hypothesis is true.\n\n-   $P(D \\mid H_0)$ is the probability of the observed data given that the null hypothesis is true.\n\n-   A **Bayes Factor greater than 1** indicates evidence in favor of $H_1$, while a **Bayes Factor less than 1** supports $H_0$.\n\nThe [**Schwarz criterion**](https://www.statisticshowto.com/bayesian-information-criterion/) (Bayesian Information Criterion, **BIC**) is one of the simplest ways to approximate the Bayes Factor.\n\n### 2.2 How to interpret Bayes Factor\n\nA **Bayes Factor** can be any positive number. One of the most common interpretations is this one---first proposed by Harold Jeffereys (1961) and slightly modified by [Lee and Wagenmakers](https://www-tandfonline-com.libproxy.smu.edu.sg/doi/pdf/10.1080/00031305.1999.10474443?needAccess=true) in 2013:\n\n![](images/image6.jpg){width=\"480\"}\n\n## 3. Hypothesis Testing\n\n### 3.1 Two-sample mean test: *ggbetweenstats()*\n\nIn the code chunk below, [*ggbetweenstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbetweenstats.html) is used to build a visual for two-sample mean test of Maths scores by gender.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex04b_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n::: panel-tabset\n### Code breakdown\n\n-   `x = GENDER` → Categorical variable (independent variable) representing gender groups (Male & Female).\n-   `y = MATHS` → Numeric variable (dependent variable) representing Maths scores.\n-   `type = \"np\"` → Specifies a nonparametric test (Mann-Whitney U test, also known as the Wilcoxon rank-sum test) instead of a parametric t-test.\n\n### Explanation of output\n\n1.  **Violin Plots**:\n    -   Show the distribution of Maths scores for **Female (left, teal)** and **Male (right, orange)**.\n    -   The width of the violin represents the density of data points.\n2.  **Boxplots Inside Violin Plots**:\n    -   The black box within each violin represents the **interquartile range (IQR)** (middle 50% of data).\n    -   The black horizontal line inside the box represents the **median**.\n    -   The whiskers extend to the smallest and largest values within 1.5 times the IQR.\n3.  **Individual Data Points**:\n    -   Each dot represents an individual student's Maths score.\n    -   Provides insight into the spread and density of scores.\n4.  **Mann-Whitney U Test Results (Top Annotation)**:\n    -   $W_{Mann-Whitney} = 13011.00$ → The Mann-Whitney U test statistic.\n    -   $p = 0.91$ → High p-value suggests no significant difference between the two groups.\n    -   $\\hat{r}_{biserial}^{rank} = 7.04e-03$ → Rank-biserial correlation effect size (very small effect).\n    -   $CI_{95\\%} [-0.12, 0.13]$ → 95% confidence interval for the effect size.\n    -   $n_{obs} = 322$ → Total number of observations (170 females, 152 males).\n\n### Key Interpretation\n\n-   The **p-value (0.91) is very high**, suggesting **no statistically significant difference** in Maths scores between genders.\n-   The **confidence interval \\[-0.12, 0.13\\] includes zero**, reinforcing the lack of a meaningful effect.\n-   The **effect size is nearly zero**, further indicating no meaningful difference in Maths performance based on gender.\n:::\n\n### 3.2 Oneway ANOVA Test: ggbetweenstats() method\n\nIn the code chunk below, `ggbetweenstats()` is used to build a visual for One-way ANOVA test on English score by race.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggbetweenstats(\n  data = exam_data,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex04b_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n::: panel-tabset\n### Code breakdown\n\n-   type = \"p\" → Performs a parametric test (Welch’s ANOVA for unequal variances).\n\n-   mean.ci = TRUE → Displays mean and confidence intervals for each group.\n\n-   pairwise.comparisons = TRUE → Conducts post-hoc pairwise comparisons (e.g., Games-Howell test for unequal variances).\n\n-   pairwise.display = \"s\" → Displays only significant comparisons in pairwise tests.\n\n    -   \"ns\" → Shows only non-significant comparisons.\n\n    -   \"s\" → Shows only significant comparisons (used in this case).\n\n    -   \"all\" → Shows all comparisons.\n\n-   p.adjust.method = \"fdr\" → Adjusts p-values for multiple comparisons using the False Discovery Rate (FDR) correction.\n\n-   messages = FALSE → Suppresses console messages.\n\n### Explanation of output\n\n\n\n### Key Interpretation\n\n\n:::\n",
    "supporting": [
      "Hands-on_Ex04b_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}